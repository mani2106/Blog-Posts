{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d2lai part3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hZmdccPFcJ70"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNE+qnYsVRyUGDwg/7tVBis"
    },
    "kernelspec": {
      "name": "python3710jvsc74a57bd0e26496a3c9db5dacfb64a364e9188c83d9facd7cc784c19023c19e60bb49263e",
      "display_name": "Python 3.7.10 64-bit ('tensor_env': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "e26496a3c9db5dacfb64a364e9188c83d9facd7cc784c19023c19e60bb49263e"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQi5cG39uB2p"
      },
      "source": [
        "# \"Linear Algebra - d2l.ai Exercises - Part 3\"\n",
        "> \"The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning\"\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [d2l.ai-exercises, deep-learning, tensorflow]\n",
        "- hide: false"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN7OrMhoXPna"
      },
      "source": [
        "## Exercise setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY0Juh-_SbJZ",
        "outputId": "ccf7baef-697a-4670-e9b3-3af430b4f87f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "A = tf.reshape(tf.range(20, dtype=tf.float32), (5,4))\n",
        "A"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.],\n",
              "       [16., 17., 18., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF3OM_8tXjFW"
      },
      "source": [
        "## Problems and answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXz9CEZ-Xo4U"
      },
      "source": [
        "### Prove that the transpose of a matrix  A â€™s transpose is  A :  $(A^{T})^T$=$A$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1fVcygYXufY"
      },
      "source": [
        "This is straightforward, transposing is basically converting rows to columns and vice-versa, so when done twice we would end up what we started with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMiQM6PqYeER",
        "outputId": "2bd51c9e-eccd-4992-c94e-2080b641d3a3"
      },
      "source": [
        "# First transpose\n",
        "At = tf.transpose(A)\n",
        "At"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 0.,  4.,  8., 12., 16.],\n",
              "       [ 1.,  5.,  9., 13., 17.],\n",
              "       [ 2.,  6., 10., 14., 18.],\n",
              "       [ 3.,  7., 11., 15., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccln-gwsYf5v",
        "outputId": "9dd56854-c01d-4426-97f6-40c0ba6367d1"
      },
      "source": [
        "# Second transpose\n",
        "At_t = tf.transpose(At)\n",
        "At_t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.],\n",
              "       [16., 17., 18., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmuepkkgY2gz",
        "outputId": "c38fd7ca-b241-462c-830b-7404bc9e5e06"
      },
      "source": [
        "At_t == A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umr5Bg5FY5OA"
      },
      "source": [
        "### Show that the sum of transposes is equal to the transpose of a sum:  $A^T+B^T=(A+B)^T$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1eCiqMiZoFU"
      },
      "source": [
        "Let's consider a second matrix, $B$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdKSmZnmZrjv",
        "outputId": "a290af0c-ebe0-4e2c-8671-eb3dc2606136"
      },
      "source": [
        "#hide_input\n",
        "B = tf.random.uniform((A.shape), minval=4, maxval=12)\n",
        "B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 7.975751 ,  7.70928  ,  8.388272 , 11.001523 ],\n",
              "       [ 7.6716766, 11.476339 ,  6.2204466,  5.6182394],\n",
              "       [ 9.765643 ,  6.7869806,  8.873018 ,  5.6852665],\n",
              "       [ 8.200825 ,  4.9842663, 11.172729 , 11.063158 ],\n",
              "       [ 8.75681  ,  8.760315 ,  4.151512 ,  5.0749035]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMUpt51DRHfO"
      },
      "source": [
        "The transpose would be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3wZ45SGZ9yY",
        "outputId": "5a8049c4-f837-4c30-9186-2c6dae9037a4"
      },
      "source": [
        "#hide_input\n",
        "Bt = tf.transpose(B)\n",
        "Bt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 7.975751 ,  7.6716766,  9.765643 ,  8.200825 ,  8.75681  ],\n",
              "       [ 7.70928  , 11.476339 ,  6.7869806,  4.9842663,  8.760315 ],\n",
              "       [ 8.388272 ,  6.2204466,  8.873018 , 11.172729 ,  4.151512 ],\n",
              "       [11.001523 ,  5.6182394,  5.6852665, 11.063158 ,  5.0749035]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNanEc55bbXL"
      },
      "source": [
        "$A^T+B^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zJZ2JdpROwf"
      },
      "source": [
        "The sum of the transposed matrices would be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsIW-hDXaTdm",
        "outputId": "5c25a9be-21c3-4132-d480-816d91b1f650"
      },
      "source": [
        "#hide_input\n",
        "indiv_trans_sum = At + Bt\n",
        "indiv_trans_sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 7.975751, 11.671677, 17.765644, 20.200825, 24.75681 ],\n",
              "       [ 8.70928 , 16.47634 , 15.786981, 17.984266, 25.760315],\n",
              "       [10.388272, 12.220447, 18.873018, 25.17273 , 22.151512],\n",
              "       [14.001523, 12.618239, 16.685266, 26.063158, 24.074903]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx29NkMvbl7Y"
      },
      "source": [
        "$(A+B)^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDtvIJnRRhsx"
      },
      "source": [
        "The transposed sum would be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCgAP7kCajEd",
        "outputId": "e5e70d10-3436-41a3-def1-79cc424ae4e4"
      },
      "source": [
        "#hide_input\n",
        "summed_trans = tf.transpose(A + B)\n",
        "summed_trans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 7.975751, 11.671677, 17.765644, 20.200825, 24.75681 ],\n",
              "       [ 8.70928 , 16.47634 , 15.786981, 17.984266, 25.760315],\n",
              "       [10.388272, 12.220447, 18.873018, 25.17273 , 22.151512],\n",
              "       [14.001523, 12.618239, 16.685266, 26.063158, 24.074903]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8idx_YWbt-k"
      },
      "source": [
        "$A^T+B^T == (A+B)^T$ ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu1AoyNBb1bh",
        "outputId": "8a7e23b0-c835-4c28-ea9a-45bd44dedbd2"
      },
      "source": [
        "#hide_input\n",
        "indiv_trans_sum == summed_trans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCd-URdcb3-C"
      },
      "source": [
        "All the numbers are equal, we can see that by looking at the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmdccPFcJ70"
      },
      "source": [
        "### Given any square matrix $A$ , is  $A+A^T$  always symmetric? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UtbUuAvdT4B"
      },
      "source": [
        "Let's define a square matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxQrcHXQLexo",
        "outputId": "493871ae-95ef-4a2f-9908-9560e3072003"
      },
      "source": [
        "#hide_input\n",
        "A = tf.reshape(tf.range(16, dtype=tf.float32), (4,4))\n",
        "A"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnhLlDnXRzq8"
      },
      "source": [
        "The tranpose of the same would be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J97tJiyMXCl",
        "outputId": "e87c4410-8d3f-468d-ca4b-b615577c2d06"
      },
      "source": [
        "At = tf.transpose(A)\n",
        "At"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  4.,  8., 12.],\n",
              "       [ 1.,  5.,  9., 13.],\n",
              "       [ 2.,  6., 10., 14.],\n",
              "       [ 3.,  7., 11., 15.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVQxMILBR3nX"
      },
      "source": [
        "The sum of the tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjrUQ0DsMgKJ",
        "outputId": "255a5cc6-c8e7-43db-99e9-6450cea6e49d"
      },
      "source": [
        "#hide_input\n",
        "A + At"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  5., 10., 15.],\n",
              "       [ 5., 10., 15., 20.],\n",
              "       [10., 15., 20., 25.],\n",
              "       [15., 20., 25., 30.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpDjvtydNEgh"
      },
      "source": [
        "Let's see if the condition stands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhu49F24MoML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f9976d-c57b-4992-cbe9-17cd7e47cd27"
      },
      "source": [
        "#hide_input\n",
        "tf.transpose(A+At) == A + At"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1u5uqxVM_d_"
      },
      "source": [
        "I guess since we add the rows and columns of the same matrix and its transpose and also since addition is commutative (ie) $A+B = B+A$, all the numbers we add endup becoming equal in terms of their respective positions, so even tranposing the resultant matrix ends up being equal to the former."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIXiYhmKOa-Q"
      },
      "source": [
        "### Output of `len(X)` for tensor $X$ shaped (2, 3, 4) and does `len(X)` always correspond to the length of a certain axis of $X$? What is that axis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOGF_E6wuNLV"
      },
      "source": [
        "Let's consider the following as $X$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYskGYzoOPV3",
        "outputId": "4ef72722-c82d-4a66-d354-0f34600e73fb"
      },
      "source": [
        "#hide_input\n",
        "X = tf.reshape(tf.range(24), (2, 3, 4))\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
              "array([[[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11]],\n",
              "\n",
              "       [[12, 13, 14, 15],\n",
              "        [16, 17, 18, 19],\n",
              "        [20, 21, 22, 23]]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvamrcHdOqWi",
        "outputId": "dcf0bcdf-6e84-48a4-f275-a7e2552ed7d4"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALMZfROgOxkp"
      },
      "source": [
        "We can see that the length returns the size of the first axis, let us see if it does the same for the other arbitrary tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USeosYVFP0zc",
        "outputId": "02db461b-2c2f-4db1-9540-fa373a0a8cf0"
      },
      "source": [
        "#hide_input\n",
        "X = tf.random.uniform((8, 1, 3), minval=4, maxval=12)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 1, 3), dtype=float32, numpy=\n",
              "array([[[11.439855 ,  5.880226 ,  5.9797716]],\n",
              "\n",
              "       [[11.37106  ,  5.619686 ,  5.9706793]],\n",
              "\n",
              "       [[ 6.4085245, 11.867535 ,  4.3086786]],\n",
              "\n",
              "       [[ 7.1461754,  8.795105 ,  8.864346 ]],\n",
              "\n",
              "       [[ 9.952526 ,  7.6806755,  7.7797728]],\n",
              "\n",
              "       [[10.933958 , 11.748696 ,  6.464444 ]],\n",
              "\n",
              "       [[ 5.296891 ,  6.7806816,  4.316203 ]],\n",
              "\n",
              "       [[ 8.316187 ,  7.272793 ,  9.020613 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCtE-pB0P7pa",
        "outputId": "ae96be01-5062-4fae-fa53-41fd078a5e61"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Uw_G0zQAD9",
        "outputId": "89829df2-8cc8-48f5-9d50-918417378bd0"
      },
      "source": [
        "#hide_input\n",
        "X = tf.random.uniform((1,2,3,9), minval=4, maxval=12)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 3, 9), dtype=float32, numpy=\n",
              "array([[[[ 5.9411087,  6.242239 ,  4.4269447,  7.913884 ,  7.8960876,\n",
              "           7.511854 ,  6.3407526, 11.290615 ,  4.5310717],\n",
              "         [ 7.182088 ,  5.086608 ,  4.0900164,  4.7155457,  8.863187 ,\n",
              "           4.1158237, 10.514992 ,  9.662274 ,  8.8960705],\n",
              "         [11.142818 ,  6.125886 ,  9.6489105,  7.8091097,  9.66531  ,\n",
              "           9.282991 ,  8.218669 , 11.877634 ,  8.727693 ]],\n",
              "\n",
              "        [[ 4.3840303,  8.792656 ,  9.48595  ,  9.231619 ,  5.972165 ,\n",
              "          11.478173 , 10.220118 , 10.394747 ,  4.430291 ],\n",
              "         [ 7.198678 ,  7.2096577,  5.8975067,  4.6933975,  6.6245346,\n",
              "          11.958464 , 10.320432 , 11.609855 ,  7.1605587],\n",
              "         [ 6.389407 ,  5.9069185,  7.974592 ,  5.289855 ,  5.713969 ,\n",
              "           6.6944523,  4.1094055,  4.077242 ,  8.026564 ]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfZjI8KkQP0h",
        "outputId": "301883e7-1eb2-4cdd-d975-90daa02936b3"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhbYNzl0QRaV"
      },
      "source": [
        "No matter what the shape of the tensor `len` always picks the first/outermost axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXAu0iU_TJEu"
      },
      "source": [
        "### What happens when we divide $A$ by the sum of it's second axis? `A / A.sum(axis=1)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ynwN7rTlSj"
      },
      "source": [
        "Let's define $A$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh8oc9BYTnmZ",
        "outputId": "ee245fd2-b869-4527-dad0-ad08538dffd7"
      },
      "source": [
        "#hide_input\n",
        "A = tf.reshape(tf.range(20, dtype=tf.float32), (5,4))\n",
        "A"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.],\n",
              "       [16., 17., 18., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "QdkArRP3Tq7N",
        "outputId": "5d14d040-8cbd-4a5b-ee20-94b2d8f0c42f"
      },
      "source": [
        "#collapse\n",
        "A / tf.reduce_sum(A, axis=1)\n",
        "# This produces an error"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Incompatible shapes: [5,4] vs. [5] [Op:RealDiv]",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-0f11f2009278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#collapse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# This produces an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1126\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m   \"\"\"\n\u001b[1;32m-> 1297\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1234\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   7440\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7441\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7442\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7443\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7444\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\envs\\tensor_env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [5,4] vs. [5] [Op:RealDiv]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVqV25UGUNVz"
      },
      "source": [
        "Ok, there seems to be shape inconsistencies to the resultant sum tensor. Let's see the sum output for the axes in tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbSpMJhXT4MW",
        "outputId": "7d752bcc-5989-4281-a57c-d4595644e24d"
      },
      "source": [
        "# Axis 1\n",
        "tf.reduce_sum(A, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 6., 22., 38., 54., 70.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix_LHf8bT8ix",
        "outputId": "a459640a-d4ed-4209-fdcd-9a3b4a73ba2d"
      },
      "source": [
        "# Axis 0\n",
        "tf.reduce_sum(A, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([40., 45., 50., 55.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTpzC3uRvMxa"
      },
      "source": [
        "So I think, When we sum a tensor on a particular axis, the shape of the resultant tensor will end taking the shape with the other remaining axes, for example a tensor with shape `(5, 4 ,3)` when summed up along the third axis `(2)` the resultant tensor would be of shape `(5, 4)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCwtuNQsw2Ij"
      },
      "source": [
        "The shapes for the tensors summed along the rest of the axes can be understood by the same.\n",
        "\n",
        "```python\n",
        "(5, 4, 3)\n",
        "\n",
        "axis = 0 : (4, 3)\n",
        "axis = 1 : (5, 3)\n",
        "axis = 2 : (5, 4)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0deW4rwWxrU4"
      },
      "source": [
        "When we do the division with the other resultant tensor, we can easily divide with it since the shapes follow the broadcasting rules\n",
        "\n",
        "```python\n",
        "       a - 5 X 4\n",
        "summed_a -     4 \n",
        "result   - 5 X 4\n",
        "```\n",
        "The following is the result of the division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_ehzczpUD_j",
        "outputId": "5c2ddbe9-6545-4d2d-8cce-8c41e7ee6927"
      },
      "source": [
        "#hide_input\n",
        "A / tf.reduce_sum(A, axis=0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[0.        , 0.02222222, 0.04      , 0.05454545],\n",
              "       [0.1       , 0.11111111, 0.12      , 0.12727273],\n",
              "       [0.2       , 0.2       , 0.2       , 0.2       ],\n",
              "       [0.3       , 0.2888889 , 0.28      , 0.27272728],\n",
              "       [0.4       , 0.37777779, 0.36      , 0.34545454]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "source": [
        "A fellow learner suggested to reframe the question [here](https://discuss.d2l.ai/t/linear-algebra/196/7?u=manimaran_p), and said that the following code is what would have been expected by the one who framed the question."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "A / tf.reshape(tf.reduce_sum(A,axis=1),(-1,1))"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[0.        , 0.16666667, 0.33333334, 0.5       ],\n",
              "       [0.18181819, 0.22727273, 0.27272728, 0.3181818 ],\n",
              "       [0.21052632, 0.23684211, 0.2631579 , 0.28947368],\n",
              "       [0.22222222, 0.24074075, 0.25925925, 0.2777778 ],\n",
              "       [0.22857143, 0.24285714, 0.25714287, 0.27142859]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "source": [
        "Let's see the shapes of the numerator and denominator of the above"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerator:  (5, 4)\nDenominator: (5, 1)\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "print(\"Numerator: \", A.shape)\n",
        "print(\"Denominator:\", tf.reshape(tf.reduce_sum(A,axis=1),(-1,1)).shape)"
      ]
    },
    {
      "source": [
        "tf.reshape(tf.reduce_sum(A,axis=1),(-1,1)), A"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
              " array([[ 6.],\n",
              "        [22.],\n",
              "        [38.],\n",
              "        [54.],\n",
              "        [70.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              " array([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15.],\n",
              "        [16., 17., 18., 19.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "source": [
        "So if we compare the values, each value in `A` has been divided by the summation of each of it's rows"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NXWNAvqUl73"
      },
      "source": [
        "### When traveling between two points in Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0Pd4Illk-F5"
      },
      "source": [
        "I am not able to get the underlying concept needed to answer this question, I have asked some [help](https://discuss.d2l.ai/t/linear-algebra/30/7?u=manimaran_p), or you can comment below to help me understand this one, thanks in advance."
      ]
    },
    {
      "source": [
        "A user suggested to look at the streets of manhattan in google maps, to understand the question better,! as suggested the maps picture looked like a big piece of land cut into several small rectangular boxes, very much like 2d coordinate space, where each intersection of street can be treated as an point in that space."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "<img src=\"../images/manhattan.png\">"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "The question asks us to find the distance that we need to cover if we need to go from one point to another in terms of streets and avenues.<br>\n",
        "Looks like there is a formula called `Manhattan distance` for a reason!\n",
        "    > The distance between two points measured along axes at right angles. In a plane with p1 at (x1, y1) and p2 at (x2, y2), it is |x1 - x2| + |y1 - y2|.\n",
        "<sub>referred from <a href=\"https://xlinux.nist.gov/dads/HTML/manhattanDistance.html\">here</a></sub>\n",
        "\n",
        "and there is also a special geometry called taxicab geometry, with manhattan distance as its metric, there are some good images and content to understand better [here](https://study.com/academy/lesson/taxicab-geometry-history-formula.html)\n",
        "\n",
        "if we need to measure the distance in terms of streets and avenues, we need to consider them as dimensions (x(street),y(avenues)), let us consider that we are in the metro point in **72nd** street and we need to go to the Jones Wood Foundry in **76th** street.\n",
        "\n",
        "Let's define them as coordinates,<br>\n",
        "72nd street, 2nd Avenue -> $(72, 2)$<br>\n",
        "76th street, 1st Avenue -> $(76, 1)$"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3bCasemlkoK"
      },
      "source": [
        "### The summation outputs for tensor with shape (2, 3, 4) along axis 0, 1, and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0_giThslxzx"
      },
      "source": [
        "I think I have answered this in the question about `A / A.sum(axis=1)`, that should apply to the any arbitrary shape, for this one it would turnout to be the following\n",
        "\n",
        "```python\n",
        "(2, 3, 4)\n",
        "\n",
        "axis = 0 : (3, 4)\n",
        "axis = 1 : (2, 4)\n",
        "axis = 2 : (2, 3)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHuRaA8nmaUt"
      },
      "source": [
        "### Feed a tensor with 3 or more axes to the `linalg.norm`.\n",
        "### What does this function compute for tensors of arbitrary shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFhzYySMmnZJ"
      },
      "source": [
        "Let's take a 3-d tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpoWSCBomwoO",
        "outputId": "17cbb588-7ecb-47bd-d0e4-0a0849741e78"
      },
      "source": [
        "#hide_input\n",
        "X = tf.reshape(tf.range(20, dtype=tf.float32), (2, 2, 5))\n",
        "X"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 5), dtype=float32, numpy=\n",
              "array([[[ 0.,  1.,  2.,  3.,  4.],\n",
              "        [ 5.,  6.,  7.,  8.,  9.]],\n",
              "\n",
              "       [[10., 11., 12., 13., 14.],\n",
              "        [15., 16., 17., 18., 19.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uQeH7kEmyht",
        "outputId": "4994e853-448f-46a2-d57f-72fa86743809"
      },
      "source": [
        "tf.norm(X)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=49.699093>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnctgYc_m7LX"
      },
      "source": [
        "Let's take an arbitrary shaped tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV69bIucslOD",
        "outputId": "108f99ab-6c88-47cf-e0ea-d3ff4bd6f94a"
      },
      "source": [
        "#hide_input\n",
        "X = tf.reshape(tf.range(80, dtype=tf.float32), (8, 1, 2, 5))\n",
        "X"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 1, 2, 5), dtype=float32, numpy=\n",
              "array([[[[ 0.,  1.,  2.,  3.,  4.],\n",
              "         [ 5.,  6.,  7.,  8.,  9.]]],\n",
              "\n",
              "\n",
              "       [[[10., 11., 12., 13., 14.],\n",
              "         [15., 16., 17., 18., 19.]]],\n",
              "\n",
              "\n",
              "       [[[20., 21., 22., 23., 24.],\n",
              "         [25., 26., 27., 28., 29.]]],\n",
              "\n",
              "\n",
              "       [[[30., 31., 32., 33., 34.],\n",
              "         [35., 36., 37., 38., 39.]]],\n",
              "\n",
              "\n",
              "       [[[40., 41., 42., 43., 44.],\n",
              "         [45., 46., 47., 48., 49.]]],\n",
              "\n",
              "\n",
              "       [[[50., 51., 52., 53., 54.],\n",
              "         [55., 56., 57., 58., 59.]]],\n",
              "\n",
              "\n",
              "       [[[60., 61., 62., 63., 64.],\n",
              "         [65., 66., 67., 68., 69.]]],\n",
              "\n",
              "\n",
              "       [[[70., 71., 72., 73., 74.],\n",
              "         [75., 76., 77., 78., 79.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev79aOhKsouD",
        "outputId": "12c23afa-bb97-4349-bd8c-947dad780864"
      },
      "source": [
        "tf.norm(X)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=409.2432>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Yv_IBNtVa3"
      },
      "source": [
        "`tf.norm` still calculates the square root of squared sum of all numbers in the tensor, equivalent to the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io4eNfY5srKS",
        "outputId": "f5586e34-6451-417d-c20b-587b245da208"
      },
      "source": [
        "tf.sqrt(\n",
        "    float(sum(\n",
        "        [x*x for x in range(80)]\n",
        "        ))\n",
        "    )"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=409.2432>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOt8AvlvtrJH"
      },
      "source": [
        "I am not sure if there was any change of behaviour expected in this, so I should try using `mxnet` to see if there is a difference in the above calculation of l2 norm."
      ]
    }
  ]
}