{"cells":[{"cell_type":"markdown","metadata":{},"source":["# \"Building தமிழ் language model\"\n","> \"In this notebook I try to build a language model for தமிழ்(Tamil) to help in some basic NLP tasks\"\n","- toc: false\n","- branch: master\n","- badges: true\n","- comments: true\n","- categories: [nlp, language-model, தமிழ்]\n","- hide: false"]},{"metadata":{"id":"9k21P-MFIfdk"},"cell_type":"markdown","source":["# Introduction"]},{"metadata":{"id":"K19SBH_VIvTU"},"cell_type":"markdown","source":["In this post, I will try to model `தமிழ்` (Tamil), I have already prepared the data for the language model in the kaggle notebook [here](https://www.kaggle.com/manimaranp/tamil-wiki-data-extraction), A language model will be useful for many tasks such as text classification, information retrieval etc."]},{"cell_type":"markdown","metadata":{},"source":["## What is a language model?"]},{"cell_type":"markdown","metadata":{},"source":["From what I know, Language model is a `machine's way of understanding` a language, technically it is defined as a probability distribution over a sequence of words[^1], by helping the machine to understand language, we can use them text-based classifiers, chatbots and for other NLP tasks in that language."]},{"cell_type":"markdown","metadata":{},"source":["## How do we train a language model?"]},{"cell_type":"markdown","metadata":{},"source":["I recall the times when you was going for school, I was given language lessons for `English` and `தமிழ்`, The languages were different in grammar, dialects, sounds etc., after some lessons about the words and letters present in the language, both of them were taught to all in the same manner.\n","\n","We would have lessons in textbooks, of which most of them are stories, biographies and history. Most of the exercises at the end of each lesson are\n","\n","- Fill in the blanks like `The ____ rises in the east.` or `சூரியன் உதிக்கும் திசை _____`\n","- Write short descriptive answers for question based on the lesson.\n","- Maybe longer essays on general `What-if` scenarios from the lesson.\n","\n","We know that to answer them, it required a decent understanding of the language's grammar, which in turn, is taught to the children by making them read and write the questions and answers."]},{"cell_type":"markdown","metadata":{},"source":["Now how can we teach a machine to understand and learn the language?, We had __textbooks__ to read and learn about the language, So the machine also needs __data__, like our textbooks (but not necessarily the same ones with which we learn) to learn the language.\n","\n","So how can we ensure that the machine is learning properly?, We test it with `Fill in the blanks` kind of exercises and let it guess the next possible word for the __sequence__ of words we give it. It will not be easy for the machine but a little bit of learning is enough to use the model for other purposes."]},{"cell_type":"markdown","metadata":{},"source":["We cannot directly give the raw text data to the model, We need to convert them to __sequence of words__ to help it learn the flow of the words"]},{"metadata":{"id":"sfZPNv_RJukO"},"cell_type":"markdown","source":["## Things we need for a language model\n","\n","- A decent amount of raw text data, more about that [here](https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html)\n","\n","- A language tokenizer, more about that [here](https://mani2106.github.io/Blog-Posts/nlp/language-model/%E0%AE%A4%E0%AE%AE%E0%AE%BF%E0%AE%B4%E0%AF%8D/2020/04/14/building-a-tokenizer-for-tamil-with-sentencepiece.html) and [here](https://mani2106.github.io/Blog-Posts/nlp/language-model/%E0%AE%A4%E0%AE%AE%E0%AE%BF%E0%AE%B4%E0%AF%8D/2020/04/14/building-a-tokenizer-for-tamil-with-sentencepiece.html)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #31708f; background-color: #d9edf7; border-color: #bce8f1;\">\n","This notebook is executed on <b><a href='https://www.kaggle.com'>kaggle</a></b>, so the paths mentioned here will be needed to change if you run in your own environment.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## Setup libraries and paths"]},{"metadata":{"id":"783i5ksvLk1p","trusted":true},"cell_type":"code","source":["#hide\n","%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","# For language modelling\n","from fastai import *\n","from fastai.text import *\n","from fastai.callbacks import *\n","from fastai.metrics import *\n","\n","# For unsupervised tokenization\n","import sentencepiece as spm\n","from pathlib import Path\n","\n","DATA_PATH = Path('/kaggle/working/Tamil-Language-data')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Set seed for reproducibility"]},{"metadata":{"trusted":true},"cell_type":"code","source":["#hide\n","seed = 42\n","\n","# python RNG\n","import random\n","random.seed(seed)\n","\n","# pytorch RNGs\n","import torch\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","# numpy RNG\n","import numpy as np\n","np.random.seed(seed)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"VHFLgdDFL-DV"},"cell_type":"markdown","source":["## Load text data from csv"]},{"metadata":{"id":"pHGUiLpBMKVV","outputId":"5b9568d6-5e51-4cb0-ae45-6b657326e55a","trusted":true},"cell_type":"code","source":["LANG_DATA = pd.read_csv(DATA_PATH/'filtered_data.csv.tar.gz', index_col=[0])\n","LANG_DATA.head()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"nLylZj17MVDj"},"cell_type":"markdown","source":["We have the `url`, `article_id` and `title` as additional information about the text, Let's check the average length of the article text."]},{"metadata":{"id":"Dbo7dSpsNiuF"},"cell_type":"markdown","source":["## Exploration"]},{"metadata":{"id":"dM7VstBUNfQR"},"cell_type":"markdown","source":["The total articles we have are `131162`"]},{"metadata":{"id":"oJpyRpBSRAyY"},"cell_type":"markdown","source":["### Remove empty articles from the dataframe"]},{"metadata":{"id":"EKslefvBRk_1","outputId":"938cecbb-1cc2-40bf-9640-d20785695549","trusted":true},"cell_type":"code","source":["LANG_DATA.dropna(axis='rows', inplace=True)\n","LANG_DATA.info()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"3rJwLfLsSWIv"},"cell_type":"markdown","source":["### Length of articles"]},{"metadata":{"id":"dS4SnSx9Mzi9","outputId":"98fbb40c-565b-4f1f-d483-4dab4adce0d8","trusted":true},"cell_type":"code","source":["#hide_input\n","sum(LANG_DATA['text'].map(str).apply(len))/LANG_DATA.shape[0]"],"execution_count":null,"outputs":[]},{"metadata":{"id":"jzTYbB0MM_OW"},"cell_type":"markdown","source":["The average length of each article is `1370` words"]},{"metadata":{"id":"rhwHe0ZTN1ET","trusted":true},"cell_type":"code","source":["#hide\n","LANG_DATA['article_length'] = LANG_DATA['text'].map(str).apply(len)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"7Gz2zU-XRuGg"},"cell_type":"markdown","source":["We had one empty article, I suppose."]},{"metadata":{"id":"zdzeBwHVUgV3"},"cell_type":"markdown","source":["# Prepare Text data for Language model"]},{"metadata":{"id":"tNfThGtIUjqz","trusted":true},"cell_type":"code","source":["processor = SPProcessor(lang='ta', sp_model=DATA_PATH/'tamil_tok.model', sp_vocab=DATA_PATH/'tamil_tok.vocab')"],"execution_count":null,"outputs":[]},{"metadata":{"id":"xKkrJhXqWqQn"},"cell_type":"markdown","source":["Set batch size"]},{"metadata":{"id":"5ilDXLW5Ws43","trusted":true},"cell_type":"code","source":["bs = 16"],"execution_count":null,"outputs":[]},{"metadata":{"id":"6tmRnAHiR-Vl","outputId":"23059e2f-cf77-410e-8c17-4d615eb6836c","trusted":true},"cell_type":"code","source":["data_lm = (TextList.from_df(LANG_DATA, path=DATA_PATH, cols='text', processor=processor)\n","            # Split out some data in a random fashion for testing\n","            .split_by_rand_pct(0.1)\n","            # This is where we convert the raw text data to \n","            # sequences of words\n","            .label_for_lm()\n","            # We want to do a language model so we label accordingly\n","            .databunch(bs=bs))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"bpz8d0f6Wvfg","trusted":true},"cell_type":"code","source":["# Check if data is loadable\n","data_lm.sanity_check()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"H7VUbQ5zfGFd"},"cell_type":"markdown","source":["Let's save the language model data to skip the processing above next time."]},{"metadata":{"id":"Bct1j5FCfMDH","trusted":true},"cell_type":"code","source":["data_lm.save(DATA_PATH/'data_lm.pkl')"],"execution_count":null,"outputs":[]},{"metadata":{"id":"G4_ryf2Afevr"},"cell_type":"markdown","source":["Let's have a look at the tokenized data from the `sentencepiece` tokenizer."]},{"metadata":{"id":"ah42h8X7fxmO","outputId":"3645b31b-b41a-44db-e13b-3451ed26dbbb","trusted":true},"cell_type":"code","source":["data_lm.show_batch()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"5AH-wOSdfybA"},"cell_type":"markdown","source":["- `bos` means beginning of the sentence.\n","- `eos` means end of the sentence.\n","- `xx maj` used to indicate the next word begins with a capital in the original text. more about this can be found [here](https://forums.fast.ai/t/xxbos-is-it-marking-beginning-of-sentence-or-beginning-of-text/43688/4?u=mani) and [here](https://docs.fast.ai/text.transform.html#Tokenizer)"]},{"metadata":{"id":"edFKRfBGf-iP"},"cell_type":"markdown","source":["# Train the language model"]},{"metadata":{"id":"ZvumNHV-86NV"},"cell_type":"markdown","source":["Initialize model"]},{"metadata":{"id":"WBLVL83thE-K","trusted":true},"cell_type":"code","source":["# To use qrnn\n","config = awd_lstm_lm_config.copy()\n","config['qrnn'] = True\n","config['n_hid'] = 1550\n","config['n_layers'] = 4\n","\n","# This is a classification metric,\n","# determines how well can the model\n","# narrow the choice of words from it's \n","# vocabulary for the next prediction.\n","perplexity = Perplexity()\n","\n","learn = language_model_learner(data_lm, arch=AWD_LSTM, config=config,\n","                               pretrained=False,\n","                                metrics=[accuracy, perplexity],\n","                              ).to_fp16()\n","# gradient clipping\n","learn.clip = 0.1\n","learn.model_dir=DATA_PATH"],"execution_count":null,"outputs":[]},{"metadata":{"id":"YOeJ2dbk7f_X"},"cell_type":"markdown","source":["## Find proper learning rate"]},{"metadata":{"id":"bpnBRuj17j6g","outputId":"8e5710e2-5a48-4c52-c60c-3d5daec1ecf6","trusted":true},"cell_type":"code","source":["learn.lr_find()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"TLw1-tKv7jlv","outputId":"6bdae7ab-fa0d-4311-cc52-688c8aebab10","trusted":true},"cell_type":"code","source":["learn.recorder.plot(suggestion=True)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"AOgo_7o27wNl"},"cell_type":"markdown","source":["Get suggested learning rate"]},{"metadata":{"id":"zxamTs4j7vo6","outputId":"fdf4b649-f62c-4e87-b124-cfc613e7cf5f","trusted":true},"cell_type":"code","source":["min_grad_lr = learn.recorder.min_grad_lr\n","min_grad_lr"],"execution_count":null,"outputs":[]},{"metadata":{"id":"QXioG_tj7344"},"cell_type":"markdown","source":["## Start training"]},{"metadata":{},"cell_type":"markdown","source":["## Stage - 1"]},{"metadata":{"id":"iXX1wHAh76ae","outputId":"58b988d0-1fdc-4bd6-e92e-f57767271636","trusted":true,"collapsed":true},"cell_type":"code","source":["learn.fit_one_cycle(10, min_grad_lr,\n","                    # Momentums, just a try!\n","                    div_factor=10.0, pct_start=0.8, moms=(0.75,0.65),\n","                    callbacks=[SaveModelCallback(learn, every='improvement', monitor='perplexity', name='best_st1'),\n","                               CSVLogger(learn, filename=DATA_PATH/'history', append=True)])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Save the intermediate results"]},{"metadata":{"trusted":true},"cell_type":"code","source":["learn.load('best_st1');\n","learn.save('ta-wiki-stage1')\n","learn.save_encoder('ta-wiki-enc-stage1')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["You can chop and change the parameters, to get a better model, find the latest run of the notebook on [kaggle](https://www.kaggle.com/manimaranp/tamil-language-model), please upvote there if you liked this."]}],"metadata":{"colab":{"name":"Tamil language model with fastai.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}