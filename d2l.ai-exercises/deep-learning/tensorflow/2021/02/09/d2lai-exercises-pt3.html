<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Linear Algebra - d2l.ai Exercises - Part 3 | Manimaran Paneerselvam’s blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Linear Algebra - d2l.ai Exercises - Part 3" />
<meta name="author" content="Manimaran Paneerselvam" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning" />
<meta property="og:description" content="The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning" />
<link rel="canonical" href="https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html" />
<meta property="og:url" content="https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html" />
<meta property="og:site_name" content="Manimaran Paneerselvam’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-09T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html","headline":"Linear Algebra - d2l.ai Exercises - Part 3","dateModified":"2021-02-09T00:00:00-06:00","datePublished":"2021-02-09T00:00:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html"},"author":{"@type":"Person","name":"Manimaran Paneerselvam"},"description":"The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Blog-Posts/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mani2106.github.io/Blog-Posts/feed.xml" title="Manimaran Paneerselvam's blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-168240544-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/Blog-Posts/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Blog-Posts/">Manimaran Paneerselvam&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Blog-Posts/about/">About Me</a><a class="page-link" href="/Blog-Posts/search/">Search</a><a class="page-link" href="/Blog-Posts/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Linear Algebra - d2l.ai Exercises - Part 3</h1><p class="page-description">The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-02-09T00:00:00-06:00" itemprop="datePublished">
        Feb 9, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#d2l.ai-exercises">d2l.ai-exercises</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#deep-learning">deep-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#tensorflow">tensorflow</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/mani2106/Blog-Posts/tree/master/_notebooks/2021-02-09-d2lai-exercises-pt3.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Blog-Posts/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/mani2106/Blog-Posts/master?filepath=_notebooks%2F2021-02-09-d2lai-exercises-pt3.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blog-Posts/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/mani2106/Blog-Posts/blob/master/_notebooks/2021-02-09-d2lai-exercises-pt3.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blog-Posts/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Exercise-setup">Exercise setup </a></li>
<li class="toc-entry toc-h2"><a href="#Problems-and-answers">Problems and answers </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Prove-that-the-transpose-of-a-matrix--A-’s-transpose-is--A-:--$(A^{T})^T$=$A$.">Prove that the transpose of a matrix  A ’s transpose is  A :  $(A^{T})^T$=$A$. </a></li>
<li class="toc-entry toc-h3"><a href="#Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--$A^T+B^T=(A+B)^T$.">Show that the sum of transposes is equal to the transpose of a sum:  $A^T+B^T=(A+B)^T$. </a></li>
<li class="toc-entry toc-h3"><a href="#Given-any-square-matrix-$A$-,-is--$A+A^T$--always-symmetric?-Why?">Given any square matrix $A$ , is  $A+A^T$  always symmetric? Why? </a></li>
<li class="toc-entry toc-h3"><a href="#Output-of-len(X)-for-tensor-$X$-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-$X$?-What-is-that-axis?">Output of len(X) for tensor $X$ shaped (2, 3, 4) and does len(X) always correspond to the length of a certain axis of $X$? What is that axis? </a></li>
<li class="toc-entry toc-h3"><a href="#What-happens-when-we-divide-$A$-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)">What happens when we divide $A$ by the sum of it&#39;s second axis? A / A.sum(axis=1) </a></li>
<li class="toc-entry toc-h3"><a href="#Question-related-to-traveling-between-two-points-in-Manhattan">Question related to traveling between two points in Manhattan </a></li>
<li class="toc-entry toc-h3"><a href="#The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2.">The summation outputs for tensor with shape (2, 3, 4) along axis 0, 1, and 2. </a></li>
<li class="toc-entry toc-h3"><a href="#Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm.">Feed a tensor with 3 or more axes to the linalg.norm. </a></li>
<li class="toc-entry toc-h3"><a href="#What-does-this-function-compute-for-tensors-of-arbitrary-shape?">What does this function compute for tensors of arbitrary shape? </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-02-09-d2lai-exercises-pt3.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Exercise-setup">
<a class="anchor" href="#Exercise-setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exercise setup<a class="anchor-link" href="#Exercise-setup"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.],
       [16., 17., 18., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Problems-and-answers">
<a class="anchor" href="#Problems-and-answers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problems and answers<a class="anchor-link" href="#Problems-and-answers"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Prove-that-the-transpose-of-a-matrix--A-’s-transpose-is--A-:--$(A^{T})^T$=$A$.">
<a class="anchor" href="#Prove-that-the-transpose-of-a-matrix--A-%E2%80%99s-transpose-is--A-:--%24(A%5E%7BT%7D)%5ET%24=%24A%24." aria-hidden="true"><span class="octicon octicon-link"></span></a>Prove that the transpose of a matrix  A ’s transpose is  A :  $(A^{T})^T$=$A$.<a class="anchor-link" href="#Prove-that-the-transpose-of-a-matrix--A-%E2%80%99s-transpose-is--A-:--%24(A%5E%7BT%7D)%5ET%24=%24A%24."> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is straightforward, transposing is basically converting rows to columns and vice-versa, so when done twice we would end up what we started with.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">At</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 0.,  4.,  8., 12., 16.],
       [ 1.,  5.,  9., 13., 17.],
       [ 2.,  6., 10., 14., 18.],
       [ 3.,  7., 11., 15., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">At</span><span class="p">)</span>
<span class="n">At_t</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.],
       [16., 17., 18., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At_t</span> <span class="o">==</span> <span class="n">A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=bool, numpy=
array([[ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--$A^T+B^T=(A+B)^T$.">
<a class="anchor" href="#Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--%24A%5ET+B%5ET=(A+B)%5ET%24." aria-hidden="true"><span class="octicon octicon-link"></span></a>Show that the sum of transposes is equal to the transpose of a sum:  $A^T+B^T=(A+B)^T$.<a class="anchor-link" href="#Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--%24A%5ET+B%5ET=(A+B)%5ET%24."> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider a second matrix, $B$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 7.975751 ,  7.70928  ,  8.388272 , 11.001523 ],
       [ 7.6716766, 11.476339 ,  6.2204466,  5.6182394],
       [ 9.765643 ,  6.7869806,  8.873018 ,  5.6852665],
       [ 8.200825 ,  4.9842663, 11.172729 , 11.063158 ],
       [ 8.75681  ,  8.760315 ,  4.151512 ,  5.0749035]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The transpose would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 7.975751 ,  7.6716766,  9.765643 ,  8.200825 ,  8.75681  ],
       [ 7.70928  , 11.476339 ,  6.7869806,  4.9842663,  8.760315 ],
       [ 8.388272 ,  6.2204466,  8.873018 , 11.172729 ,  4.151512 ],
       [11.001523 ,  5.6182394,  5.6852665, 11.063158 ,  5.0749035]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$A^T+B^T$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sum of the transposed matrices would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 7.975751, 11.671677, 17.765644, 20.200825, 24.75681 ],
       [ 8.70928 , 16.47634 , 15.786981, 17.984266, 25.760315],
       [10.388272, 12.220447, 18.873018, 25.17273 , 22.151512],
       [14.001523, 12.618239, 16.685266, 26.063158, 24.074903]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$(A+B)^T$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The transposed sum would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 7.975751, 11.671677, 17.765644, 20.200825, 24.75681 ],
       [ 8.70928 , 16.47634 , 15.786981, 17.984266, 25.760315],
       [10.388272, 12.220447, 18.873018, 25.17273 , 22.151512],
       [14.001523, 12.618239, 16.685266, 26.063158, 24.074903]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$A^T+B^T == (A+B)^T$ ?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All the numbers are equal, we can see that by looking at the results</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Given-any-square-matrix-$A$-,-is--$A+A^T$--always-symmetric?-Why?">
<a class="anchor" href="#Given-any-square-matrix-%24A%24-,-is--%24A+A%5ET%24--always-symmetric?-Why?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Given any square matrix $A$ , is  $A+A^T$  always symmetric? Why?<a class="anchor-link" href="#Given-any-square-matrix-%24A%24-,-is--%24A+A%5ET%24--always-symmetric?-Why?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define a square matrix</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The tranpose of the same would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">At</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[ 0.,  4.,  8., 12.],
       [ 1.,  5.,  9., 13.],
       [ 2.,  6., 10., 14.],
       [ 3.,  7., 11., 15.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sum of the tensors</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[ 0.,  5., 10., 15.],
       [ 5., 10., 15., 20.],
       [10., 15., 20., 25.],
       [15., 20., 25., 30.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see if the condition stands</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=bool, numpy=
array([[ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I guess since we add the rows and columns of the same matrix and its transpose and also since addition is commutative (ie) $A+B = B+A$, all the numbers we add endup becoming equal in terms of their respective positions, so even tranposing the resultant matrix ends up being equal to the former.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-of-len(X)-for-tensor-$X$-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-$X$?-What-is-that-axis?">
<a class="anchor" href="#Output-of-len(X)-for-tensor-%24X%24-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-%24X%24?-What-is-that-axis?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Output of <code>len(X)</code> for tensor $X$ shaped (2, 3, 4) and does <code>len(X)</code> always correspond to the length of a certain axis of $X$? What is that axis?<a class="anchor-link" href="#Output-of-len(X)-for-tensor-%24X%24-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-%24X%24?-What-is-that-axis?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider the following as $X$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=
array([[[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]],

       [[12, 13, 14, 15],
        [16, 17, 18, 19],
        [20, 21, 22, 23]]], dtype=int32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>2</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the length returns the size of the first axis, let us see if it does the same for the other arbitrary tensors</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(8, 1, 3), dtype=float32, numpy=
array([[[11.439855 ,  5.880226 ,  5.9797716]],

       [[11.37106  ,  5.619686 ,  5.9706793]],

       [[ 6.4085245, 11.867535 ,  4.3086786]],

       [[ 7.1461754,  8.795105 ,  8.864346 ]],

       [[ 9.952526 ,  7.6806755,  7.7797728]],

       [[10.933958 , 11.748696 ,  6.464444 ]],

       [[ 5.296891 ,  6.7806816,  4.316203 ]],

       [[ 8.316187 ,  7.272793 ,  9.020613 ]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>8</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(1, 2, 3, 9), dtype=float32, numpy=
array([[[[ 5.9411087,  6.242239 ,  4.4269447,  7.913884 ,  7.8960876,
           7.511854 ,  6.3407526, 11.290615 ,  4.5310717],
         [ 7.182088 ,  5.086608 ,  4.0900164,  4.7155457,  8.863187 ,
           4.1158237, 10.514992 ,  9.662274 ,  8.8960705],
         [11.142818 ,  6.125886 ,  9.6489105,  7.8091097,  9.66531  ,
           9.282991 ,  8.218669 , 11.877634 ,  8.727693 ]],

        [[ 4.3840303,  8.792656 ,  9.48595  ,  9.231619 ,  5.972165 ,
          11.478173 , 10.220118 , 10.394747 ,  4.430291 ],
         [ 7.198678 ,  7.2096577,  5.8975067,  4.6933975,  6.6245346,
          11.958464 , 10.320432 , 11.609855 ,  7.1605587],
         [ 6.389407 ,  5.9069185,  7.974592 ,  5.289855 ,  5.713969 ,
           6.6944523,  4.1094055,  4.077242 ,  8.026564 ]]]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>No matter what the shape of the tensor <code>len</code> always picks the first/outermost axis.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-happens-when-we-divide-$A$-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)">
<a class="anchor" href="#What-happens-when-we-divide-%24A%24-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)" aria-hidden="true"><span class="octicon octicon-link"></span></a>What happens when we divide $A$ by the sum of it's second axis? <code>A / A.sum(axis=1)</code><a class="anchor-link" href="#What-happens-when-we-divide-%24A%24-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define $A$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.],
       [16., 17., 18., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">A</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">InvalidArgumentError</span>                      Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-12-6e6b244e22c4&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>A <span class="ansi-blue-fg">/</span> tf<span class="ansi-blue-fg">.</span>reduce_sum<span class="ansi-blue-fg">(</span>A<span class="ansi-blue-fg">,</span> axis<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py</span> in <span class="ansi-cyan-fg">binary_op_wrapper</span><span class="ansi-blue-fg">(x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">   1162</span>     <span class="ansi-green-fg">with</span> ops<span class="ansi-blue-fg">.</span>name_scope<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> op_name<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">[</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">as</span> name<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1163</span>       <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1164</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span>name<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1165</span>       <span class="ansi-green-fg">except</span> <span class="ansi-blue-fg">(</span>TypeError<span class="ansi-blue-fg">,</span> ValueError<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1166</span>         <span class="ansi-red-fg"># Even if dispatching the op failed, the RHS may be a tensor aware</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py</span> in <span class="ansi-cyan-fg">wrapper</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    199</span>     <span class="ansi-blue-fg">"""Call target, and fall back on dispatchers if there is a TypeError."""</span>
<span class="ansi-green-intense-fg ansi-bold">    200</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 201</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> target<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    202</span>     <span class="ansi-green-fg">except</span> <span class="ansi-blue-fg">(</span>TypeError<span class="ansi-blue-fg">,</span> ValueError<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    203</span>       <span class="ansi-red-fg"># Note: convert_to_eager_tensor currently raises a ValueError, not a</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py</span> in <span class="ansi-cyan-fg">truediv</span><span class="ansi-blue-fg">(x, y, name)</span>
<span class="ansi-green-intense-fg ansi-bold">   1334</span>     TypeError<span class="ansi-blue-fg">:</span> If<span class="ansi-red-fg"> </span><span class="ansi-red-fg">`</span>x<span class="ansi-red-fg">`</span> <span class="ansi-green-fg">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">`</span>y<span class="ansi-red-fg">`</span> have different dtypes<span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">   1335</span>   """
<span class="ansi-green-fg">-&gt; 1336</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> _truediv_python3<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1337</span> 
<span class="ansi-green-intense-fg ansi-bold">   1338</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py</span> in <span class="ansi-cyan-fg">_truediv_python3</span><span class="ansi-blue-fg">(x, y, name)</span>
<span class="ansi-green-intense-fg ansi-bold">   1273</span>       x <span class="ansi-blue-fg">=</span> cast<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1274</span>       y <span class="ansi-blue-fg">=</span> cast<span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1275</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> gen_math_ops<span class="ansi-blue-fg">.</span>real_div<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span>name<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1276</span> 
<span class="ansi-green-intense-fg ansi-bold">   1277</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py</span> in <span class="ansi-cyan-fg">real_div</span><span class="ansi-blue-fg">(x, y, name)</span>
<span class="ansi-green-intense-fg ansi-bold">   7327</span>       <span class="ansi-green-fg">return</span> _result
<span class="ansi-green-intense-fg ansi-bold">   7328</span>     <span class="ansi-green-fg">except</span> _core<span class="ansi-blue-fg">.</span>_NotOkStatusException <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 7329</span><span class="ansi-red-fg">       </span>_ops<span class="ansi-blue-fg">.</span>raise_from_not_ok_status<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   7330</span>     <span class="ansi-green-fg">except</span> _core<span class="ansi-blue-fg">.</span>_FallbackException<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   7331</span>       <span class="ansi-green-fg">pass</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py</span> in <span class="ansi-cyan-fg">raise_from_not_ok_status</span><span class="ansi-blue-fg">(e, name)</span>
<span class="ansi-green-intense-fg ansi-bold">   6860</span>   message <span class="ansi-blue-fg">=</span> e<span class="ansi-blue-fg">.</span>message <span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">" name: "</span> <span class="ansi-blue-fg">+</span> name <span class="ansi-green-fg">if</span> name <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">else</span> <span class="ansi-blue-fg">""</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   6861</span>   <span class="ansi-red-fg"># pylint: disable=protected-access</span>
<span class="ansi-green-fg">-&gt; 6862</span><span class="ansi-red-fg">   </span>six<span class="ansi-blue-fg">.</span>raise_from<span class="ansi-blue-fg">(</span>core<span class="ansi-blue-fg">.</span>_status_to_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">.</span>code<span class="ansi-blue-fg">,</span> message<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   6863</span>   <span class="ansi-red-fg"># pylint: enable=protected-access</span>
<span class="ansi-green-intense-fg ansi-bold">   6864</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/six.py</span> in <span class="ansi-cyan-fg">raise_from</span><span class="ansi-blue-fg">(value, from_value)</span>

<span class="ansi-red-fg">InvalidArgumentError</span>: Incompatible shapes: [5,4] vs. [5] [Op:RealDiv]</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, there seems to be shape inconsistencies to the resultant sum tensor. Let's see the sum output for the axes in tensor.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 6., 22., 38., 54., 70.], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([40., 45., 50., 55.], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So I think, When we sum a tensor on a particular axis, the shape of the resultant tensor will end taking the shape with the other remaining axes, for example a tensor with shape <code>(5, 4 ,3)</code> when summed up along the third axis <code>(2)</code> the resultant tensor would be of shape <code>(5, 4)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The shapes for the tensors summed along the rest of the axes can be understood by the same.</p>
<div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When we do the division with the other resultant tensor, we can easily divide with it since the shapes follow the broadcasting rules</p>
<div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">-</span> <span class="mi">5</span> <span class="n">X</span> <span class="mi">4</span>
<span class="n">summed_a</span> <span class="o">-</span>     <span class="mi">4</span> 
<span class="n">result</span>   <span class="o">-</span> <span class="mi">5</span> <span class="n">X</span> <span class="mi">4</span>
</pre></div>
<p>The following is the result of the division</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[0.        , 0.02222222, 0.04      , 0.05454545],
       [0.1       , 0.11111111, 0.12      , 0.12727273],
       [0.2       , 0.2       , 0.2       , 0.2       ],
       [0.3       , 0.2888889 , 0.28      , 0.27272728],
       [0.4       , 0.37777779, 0.36      , 0.34545454]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Question-related-to-traveling-between-two-points-in-Manhattan">
<a class="anchor" href="#Question-related-to-traveling-between-two-points-in-Manhattan" aria-hidden="true"><span class="octicon octicon-link"></span></a>Question related to traveling between two points in Manhattan<a class="anchor-link" href="#Question-related-to-traveling-between-two-points-in-Manhattan"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I am not able to get the underlying concept needed to answer this question, I have asked some <a href="https://discuss.d2l.ai/t/linear-algebra/30/7?u=manimaran_p">help</a>, or you can comment below to help me understand this one, thanks in advance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2.">
<a class="anchor" href="#The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2." aria-hidden="true"><span class="octicon octicon-link"></span></a>The summation outputs for tensor with shape (2, 3, 4) along axis 0, 1, and 2.<a class="anchor-link" href="#The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2."> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I think I have answered this in the question about <code>A / A.sum(axis=1)</code>, that should apply to the any arbitrary shape, for this one it would turnout to be the following</p>
<div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm.">
<a class="anchor" href="#Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm." aria-hidden="true"><span class="octicon octicon-link"></span></a>Feed a tensor with 3 or more axes to the <code>linalg.norm</code>.<a class="anchor-link" href="#Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm."> </a>
</h3>
<h3 id="What-does-this-function-compute-for-tensors-of-arbitrary-shape?">
<a class="anchor" href="#What-does-this-function-compute-for-tensors-of-arbitrary-shape?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What does this function compute for tensors of arbitrary shape?<a class="anchor-link" href="#What-does-this-function-compute-for-tensors-of-arbitrary-shape?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a 3-d tensor</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(2, 2, 5), dtype=float32, numpy=
array([[[ 0.,  1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.,  9.]],

       [[10., 11., 12., 13., 14.],
        [15., 16., 17., 18., 19.]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(), dtype=float32, numpy=49.699093&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take an arbitrary shaped tensor</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(8, 1, 2, 5), dtype=float32, numpy=
array([[[[ 0.,  1.,  2.,  3.,  4.],
         [ 5.,  6.,  7.,  8.,  9.]]],


       [[[10., 11., 12., 13., 14.],
         [15., 16., 17., 18., 19.]]],


       [[[20., 21., 22., 23., 24.],
         [25., 26., 27., 28., 29.]]],


       [[[30., 31., 32., 33., 34.],
         [35., 36., 37., 38., 39.]]],


       [[[40., 41., 42., 43., 44.],
         [45., 46., 47., 48., 49.]]],


       [[[50., 51., 52., 53., 54.],
         [55., 56., 57., 58., 59.]]],


       [[[60., 61., 62., 63., 64.],
         [65., 66., 67., 68., 69.]]],


       [[[70., 71., 72., 73., 74.],
         [75., 76., 77., 78., 79.]]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(), dtype=float32, numpy=409.2432&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>tf.norm</code> still calculates the square root of squared sum of all numbers in the tensor, equivalent to the following</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
    <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">80</span><span class="p">)]</span>
        <span class="p">))</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(), dtype=float32, numpy=409.2432&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I am not sure if there was any change of behaviour expected in this, so I should try using <code>mxnet</code> to see if there is a difference in the above calculation of l2 norm.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="mani2106/Blog-Posts"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Blog-Posts/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Blog-Posts/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Manimaran Paneerselvam</li>
          <li><a class="u-email" href="mailto:manimaran_p@outlook.com">manimaran_p@outlook.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>This is where I write about my work on data science. I will also post Notebooks and sample codes to solve some interesting problems that I face everyday.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/mani2106" title="mani2106"><svg class="svg-icon grey"><use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/manimaran-p" title="manimaran-p"><svg class="svg-icon grey"><use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
