<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Linear Algebra - d2l.ai Exercises - Part 3 | Manimaran Paneerselvam’s blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Linear Algebra - d2l.ai Exercises - Part 3" />
<meta name="author" content="Manimaran Paneerselvam" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning" />
<meta property="og:description" content="The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning" />
<link rel="canonical" href="https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html" />
<meta property="og:url" content="https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html" />
<meta property="og:site_name" content="Manimaran Paneerselvam’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-09T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html"},"url":"https://mani2106.github.io/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html","@type":"BlogPosting","author":{"@type":"Person","name":"Manimaran Paneerselvam"},"headline":"Linear Algebra - d2l.ai Exercises - Part 3","dateModified":"2021-02-09T00:00:00-06:00","datePublished":"2021-02-09T00:00:00-06:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Blog-Posts/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mani2106.github.io/Blog-Posts/feed.xml" title="Manimaran Paneerselvam's blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-168240544-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-168240544-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/Blog-Posts/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Blog-Posts/">Manimaran Paneerselvam&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Blog-Posts/about/">About Me</a><a class="page-link" href="/Blog-Posts/search/">Search</a><a class="page-link" href="/Blog-Posts/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Linear Algebra - d2l.ai Exercises - Part 3</h1><p class="page-description">The third notebook in a series to be posted aiming to solve and understand exercises from d2l.ai curriculum on deep learning</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-02-09T00:00:00-06:00" itemprop="datePublished">
        Feb 9, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      11 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#d2l.ai-exercises">d2l.ai-exercises</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#deep-learning">deep-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#tensorflow">tensorflow</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/mani2106/Blog-Posts/tree/master/_notebooks/2021-02-09-d2lai-exercises-pt3.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Blog-Posts/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/mani2106/Blog-Posts/master?filepath=_notebooks%2F2021-02-09-d2lai-exercises-pt3.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blog-Posts/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/mani2106/Blog-Posts/blob/master/_notebooks/2021-02-09-d2lai-exercises-pt3.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blog-Posts/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Exercise-setup">Exercise setup </a></li>
<li class="toc-entry toc-h2"><a href="#Problems-and-answers">Problems and answers </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Prove-that-the-transpose-of-a-matrix--A-’s-transpose-is--A-:--$(A^{T})^T$=$A$.">Prove that the transpose of a matrix  A ’s transpose is  A :  $(A^{T})^T$=$A$. </a></li>
<li class="toc-entry toc-h3"><a href="#Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--$A^T+B^T=(A+B)^T$.">Show that the sum of transposes is equal to the transpose of a sum:  $A^T+B^T=(A+B)^T$. </a></li>
<li class="toc-entry toc-h3"><a href="#Given-any-square-matrix-$A$-,-is--$A+A^T$--always-symmetric?-Why?">Given any square matrix $A$ , is  $A+A^T$  always symmetric? Why? </a></li>
<li class="toc-entry toc-h3"><a href="#Output-of-len(X)-for-tensor-$X$-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-$X$?-What-is-that-axis?">Output of len(X) for tensor $X$ shaped (2, 3, 4) and does len(X) always correspond to the length of a certain axis of $X$? What is that axis? </a></li>
<li class="toc-entry toc-h3"><a href="#What-happens-when-we-divide-$A$-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)">What happens when we divide $A$ by the sum of it&#39;s second axis? A / A.sum(axis=1) </a></li>
<li class="toc-entry toc-h3"><a href="#When-traveling-between-two-points-in-Manhattan,-what-is-the-distance-that-you-need-to-cover-in-terms-of-the-coordinates,-i.e.,-in-terms-of-avenues-and-streets?-Can-you-travel-diagonally?">When traveling between two points in Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally? </a></li>
<li class="toc-entry toc-h3"><a href="#The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2.">The summation outputs for tensor with shape (2, 3, 4) along axis 0, 1, and 2. </a></li>
<li class="toc-entry toc-h3"><a href="#Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm.">Feed a tensor with 3 or more axes to the linalg.norm. </a></li>
<li class="toc-entry toc-h3"><a href="#What-does-this-function-compute-for-tensors-of-arbitrary-shape?">What does this function compute for tensors of arbitrary shape? </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-02-09-d2lai-exercises-pt3.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Exercise-setup">
<a class="anchor" href="#Exercise-setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exercise setup<a class="anchor-link" href="#Exercise-setup"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.],
       [16., 17., 18., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Problems-and-answers">
<a class="anchor" href="#Problems-and-answers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problems and answers<a class="anchor-link" href="#Problems-and-answers"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Prove-that-the-transpose-of-a-matrix--A-’s-transpose-is--A-:--$(A^{T})^T$=$A$.">
<a class="anchor" href="#Prove-that-the-transpose-of-a-matrix--A-%E2%80%99s-transpose-is--A-:--%24(A%5E%7BT%7D)%5ET%24=%24A%24." aria-hidden="true"><span class="octicon octicon-link"></span></a>Prove that the transpose of a matrix  A ’s transpose is  A :  $(A^{T})^T$=$A$.<a class="anchor-link" href="#Prove-that-the-transpose-of-a-matrix--A-%E2%80%99s-transpose-is--A-:--%24(A%5E%7BT%7D)%5ET%24=%24A%24."> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is straightforward, transposing is basically converting rows to columns and vice-versa, so when done twice we would end up what we started with.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">At</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 0.,  4.,  8., 12., 16.],
       [ 1.,  5.,  9., 13., 17.],
       [ 2.,  6., 10., 14., 18.],
       [ 3.,  7., 11., 15., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">At</span><span class="p">)</span>
<span class="n">At_t</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.],
       [16., 17., 18., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At_t</span> <span class="o">==</span> <span class="n">A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=bool, numpy=
array([[ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--$A^T+B^T=(A+B)^T$.">
<a class="anchor" href="#Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--%24A%5ET+B%5ET=(A+B)%5ET%24." aria-hidden="true"><span class="octicon octicon-link"></span></a>Show that the sum of transposes is equal to the transpose of a sum:  $A^T+B^T=(A+B)^T$.<a class="anchor-link" href="#Show-that-the-sum-of-transposes-is-equal-to-the-transpose-of-a-sum:--%24A%5ET+B%5ET=(A+B)%5ET%24."> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider a second matrix, $B$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 7.975751 ,  7.70928  ,  8.388272 , 11.001523 ],
       [ 7.6716766, 11.476339 ,  6.2204466,  5.6182394],
       [ 9.765643 ,  6.7869806,  8.873018 ,  5.6852665],
       [ 8.200825 ,  4.9842663, 11.172729 , 11.063158 ],
       [ 8.75681  ,  8.760315 ,  4.151512 ,  5.0749035]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The transpose would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 7.975751 ,  7.6716766,  9.765643 ,  8.200825 ,  8.75681  ],
       [ 7.70928  , 11.476339 ,  6.7869806,  4.9842663,  8.760315 ],
       [ 8.388272 ,  6.2204466,  8.873018 , 11.172729 ,  4.151512 ],
       [11.001523 ,  5.6182394,  5.6852665, 11.063158 ,  5.0749035]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$A^T+B^T$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sum of the transposed matrices would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 7.975751, 11.671677, 17.765644, 20.200825, 24.75681 ],
       [ 8.70928 , 16.47634 , 15.786981, 17.984266, 25.760315],
       [10.388272, 12.220447, 18.873018, 25.17273 , 22.151512],
       [14.001523, 12.618239, 16.685266, 26.063158, 24.074903]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$(A+B)^T$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The transposed sum would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 7.975751, 11.671677, 17.765644, 20.200825, 24.75681 ],
       [ 8.70928 , 16.47634 , 15.786981, 17.984266, 25.760315],
       [10.388272, 12.220447, 18.873018, 25.17273 , 22.151512],
       [14.001523, 12.618239, 16.685266, 26.063158, 24.074903]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$A^T+B^T == (A+B)^T$ ?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 5), dtype=bool, numpy=
array([[ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True],
       [ True,  True,  True,  True,  True]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All the numbers are equal, we can see that by looking at the results</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Given-any-square-matrix-$A$-,-is--$A+A^T$--always-symmetric?-Why?">
<a class="anchor" href="#Given-any-square-matrix-%24A%24-,-is--%24A+A%5ET%24--always-symmetric?-Why?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Given any square matrix $A$ , is  $A+A^T$  always symmetric? Why?<a class="anchor-link" href="#Given-any-square-matrix-%24A%24-,-is--%24A+A%5ET%24--always-symmetric?-Why?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define a square matrix</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The tranpose of the same would be</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">At</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">At</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[ 0.,  4.,  8., 12.],
       [ 1.,  5.,  9., 13.],
       [ 2.,  6., 10., 14.],
       [ 3.,  7., 11., 15.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sum of the tensors</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[ 0.,  5., 10., 15.],
       [ 5., 10., 15., 20.],
       [10., 15., 20., 25.],
       [15., 20., 25., 30.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see if the condition stands</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4, 4), dtype=bool, numpy=
array([[ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True],
       [ True,  True,  True,  True]])&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I guess since we add the rows and columns of the same matrix and its transpose and also since addition is commutative (ie) $A+B = B+A$, all the numbers we add endup becoming equal in terms of their respective positions, so even tranposing the resultant matrix ends up being equal to the former.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-of-len(X)-for-tensor-$X$-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-$X$?-What-is-that-axis?">
<a class="anchor" href="#Output-of-len(X)-for-tensor-%24X%24-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-%24X%24?-What-is-that-axis?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Output of <code>len(X)</code> for tensor $X$ shaped (2, 3, 4) and does <code>len(X)</code> always correspond to the length of a certain axis of $X$? What is that axis?<a class="anchor-link" href="#Output-of-len(X)-for-tensor-%24X%24-shaped-(2,-3,-4)-and-does-len(X)-always-correspond-to-the-length-of-a-certain-axis-of-%24X%24?-What-is-that-axis?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider the following as $X$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=
array([[[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]],

       [[12, 13, 14, 15],
        [16, 17, 18, 19],
        [20, 21, 22, 23]]], dtype=int32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>2</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the length returns the size of the first axis, let us see if it does the same for the other arbitrary tensors</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(8, 1, 3), dtype=float32, numpy=
array([[[11.439855 ,  5.880226 ,  5.9797716]],

       [[11.37106  ,  5.619686 ,  5.9706793]],

       [[ 6.4085245, 11.867535 ,  4.3086786]],

       [[ 7.1461754,  8.795105 ,  8.864346 ]],

       [[ 9.952526 ,  7.6806755,  7.7797728]],

       [[10.933958 , 11.748696 ,  6.464444 ]],

       [[ 5.296891 ,  6.7806816,  4.316203 ]],

       [[ 8.316187 ,  7.272793 ,  9.020613 ]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>8</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(1, 2, 3, 9), dtype=float32, numpy=
array([[[[ 5.9411087,  6.242239 ,  4.4269447,  7.913884 ,  7.8960876,
           7.511854 ,  6.3407526, 11.290615 ,  4.5310717],
         [ 7.182088 ,  5.086608 ,  4.0900164,  4.7155457,  8.863187 ,
           4.1158237, 10.514992 ,  9.662274 ,  8.8960705],
         [11.142818 ,  6.125886 ,  9.6489105,  7.8091097,  9.66531  ,
           9.282991 ,  8.218669 , 11.877634 ,  8.727693 ]],

        [[ 4.3840303,  8.792656 ,  9.48595  ,  9.231619 ,  5.972165 ,
          11.478173 , 10.220118 , 10.394747 ,  4.430291 ],
         [ 7.198678 ,  7.2096577,  5.8975067,  4.6933975,  6.6245346,
          11.958464 , 10.320432 , 11.609855 ,  7.1605587],
         [ 6.389407 ,  5.9069185,  7.974592 ,  5.289855 ,  5.713969 ,
           6.6944523,  4.1094055,  4.077242 ,  8.026564 ]]]],
      dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>No matter what the shape of the tensor <code>len</code> always picks the first/outermost axis.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-happens-when-we-divide-$A$-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)">
<a class="anchor" href="#What-happens-when-we-divide-%24A%24-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)" aria-hidden="true"><span class="octicon octicon-link"></span></a>What happens when we divide $A$ by the sum of it's second axis? <code>A / A.sum(axis=1)</code><a class="anchor-link" href="#What-happens-when-we-divide-%24A%24-by-the-sum-of-it's-second-axis?-A-/-A.sum(axis=1)"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define $A$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.],
       [12., 13., 14., 15.],
       [16., 17., 18., 19.]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">A</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># This produces an error</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">InvalidArgumentError</span>                      Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-4-0f11f2009278&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">      1</span> <span class="ansi-red-intense-fg ansi-bold">#collapse</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 2</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>A <span class="ansi-yellow-intense-fg ansi-bold">/</span> tf<span class="ansi-yellow-intense-fg ansi-bold">.</span>reduce_sum<span class="ansi-yellow-intense-fg ansi-bold">(</span>A<span class="ansi-yellow-intense-fg ansi-bold">,</span> axis<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">1</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">      3</span> <span class="ansi-red-intense-fg ansi-bold"># This produces an error</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\tensorflow\python\ops\math_ops.py</span> in <span class="ansi-cyan-fg">binary_op_wrapper</span><span class="ansi-blue-intense-fg ansi-bold">(x, y)</span>
<span class="ansi-green-fg">   1123</span>     <span class="ansi-green-intense-fg ansi-bold">with</span> ops<span class="ansi-yellow-intense-fg ansi-bold">.</span>name_scope<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> op_name<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">[</span>x<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">]</span><span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-green-intense-fg ansi-bold">as</span> name<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">   1124</span>       <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1125</span><span class="ansi-yellow-intense-fg ansi-bold">         </span><span class="ansi-green-intense-fg ansi-bold">return</span> func<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">,</span> name<span class="ansi-yellow-intense-fg ansi-bold">=</span>name<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1126</span>       <span class="ansi-green-intense-fg ansi-bold">except</span> <span class="ansi-yellow-intense-fg ansi-bold">(</span>TypeError<span class="ansi-yellow-intense-fg ansi-bold">,</span> ValueError<span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-green-intense-fg ansi-bold">as</span> e<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">   1127</span>         <span class="ansi-red-intense-fg ansi-bold"># Even if dispatching the op failed, the RHS may be a tensor aware</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\tensorflow\python\util\dispatch.py</span> in <span class="ansi-cyan-fg">wrapper</span><span class="ansi-blue-intense-fg ansi-bold">(*args, **kwargs)</span>
<span class="ansi-green-fg">    199</span>     <span class="ansi-blue-intense-fg ansi-bold">"""Call target, and fall back on dispatchers if there is a TypeError."""</span>
<span class="ansi-green-fg">    200</span>     <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 201</span><span class="ansi-yellow-intense-fg ansi-bold">       </span><span class="ansi-green-intense-fg ansi-bold">return</span> target<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>args<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kwargs<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    202</span>     <span class="ansi-green-intense-fg ansi-bold">except</span> <span class="ansi-yellow-intense-fg ansi-bold">(</span>TypeError<span class="ansi-yellow-intense-fg ansi-bold">,</span> ValueError<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    203</span>       <span class="ansi-red-intense-fg ansi-bold"># Note: convert_to_eager_tensor currently raises a ValueError, not a</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\tensorflow\python\ops\math_ops.py</span> in <span class="ansi-cyan-fg">truediv</span><span class="ansi-blue-intense-fg ansi-bold">(x, y, name)</span>
<span class="ansi-green-fg">   1295</span>     TypeError<span class="ansi-yellow-intense-fg ansi-bold">:</span> If<span class="ansi-red-fg"> </span><span class="ansi-red-fg">`</span>x<span class="ansi-red-fg">`</span> <span class="ansi-green-intense-fg ansi-bold">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">`</span>y<span class="ansi-red-fg">`</span> have different dtypes<span class="ansi-yellow-intense-fg ansi-bold">.</span>
<span class="ansi-green-fg">   1296</span>   """
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1297</span><span class="ansi-yellow-intense-fg ansi-bold">   </span><span class="ansi-green-intense-fg ansi-bold">return</span> _truediv_python3<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">,</span> name<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1298</span> 
<span class="ansi-green-fg">   1299</span> 

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\tensorflow\python\ops\math_ops.py</span> in <span class="ansi-cyan-fg">_truediv_python3</span><span class="ansi-blue-intense-fg ansi-bold">(x, y, name)</span>
<span class="ansi-green-fg">   1234</span>       x <span class="ansi-yellow-intense-fg ansi-bold">=</span> cast<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1235</span>       y <span class="ansi-yellow-intense-fg ansi-bold">=</span> cast<span class="ansi-yellow-intense-fg ansi-bold">(</span>y<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1236</span><span class="ansi-yellow-intense-fg ansi-bold">     </span><span class="ansi-green-intense-fg ansi-bold">return</span> gen_math_ops<span class="ansi-yellow-intense-fg ansi-bold">.</span>real_div<span class="ansi-yellow-intense-fg ansi-bold">(</span>x<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">,</span> name<span class="ansi-yellow-intense-fg ansi-bold">=</span>name<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1237</span> 
<span class="ansi-green-fg">   1238</span> 

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\tensorflow\python\ops\gen_math_ops.py</span> in <span class="ansi-cyan-fg">real_div</span><span class="ansi-blue-intense-fg ansi-bold">(x, y, name)</span>
<span class="ansi-green-fg">   7440</span>       <span class="ansi-green-intense-fg ansi-bold">return</span> _result
<span class="ansi-green-fg">   7441</span>     <span class="ansi-green-intense-fg ansi-bold">except</span> _core<span class="ansi-yellow-intense-fg ansi-bold">.</span>_NotOkStatusException <span class="ansi-green-intense-fg ansi-bold">as</span> e<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 7442</span><span class="ansi-yellow-intense-fg ansi-bold">       </span>_ops<span class="ansi-yellow-intense-fg ansi-bold">.</span>raise_from_not_ok_status<span class="ansi-yellow-intense-fg ansi-bold">(</span>e<span class="ansi-yellow-intense-fg ansi-bold">,</span> name<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   7443</span>     <span class="ansi-green-intense-fg ansi-bold">except</span> _core<span class="ansi-yellow-intense-fg ansi-bold">.</span>_FallbackException<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">   7444</span>       <span class="ansi-green-intense-fg ansi-bold">pass</span>

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\tensorflow\python\framework\ops.py</span> in <span class="ansi-cyan-fg">raise_from_not_ok_status</span><span class="ansi-blue-intense-fg ansi-bold">(e, name)</span>
<span class="ansi-green-fg">   6841</span>   message <span class="ansi-yellow-intense-fg ansi-bold">=</span> e<span class="ansi-yellow-intense-fg ansi-bold">.</span>message <span class="ansi-yellow-intense-fg ansi-bold">+</span> <span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">" name: "</span> <span class="ansi-yellow-intense-fg ansi-bold">+</span> name <span class="ansi-green-intense-fg ansi-bold">if</span> name <span class="ansi-green-intense-fg ansi-bold">is</span> <span class="ansi-green-intense-fg ansi-bold">not</span> <span class="ansi-green-intense-fg ansi-bold">None</span> <span class="ansi-green-intense-fg ansi-bold">else</span> <span class="ansi-blue-intense-fg ansi-bold">""</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   6842</span>   <span class="ansi-red-intense-fg ansi-bold"># pylint: disable=protected-access</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 6843</span><span class="ansi-yellow-intense-fg ansi-bold">   </span>six<span class="ansi-yellow-intense-fg ansi-bold">.</span>raise_from<span class="ansi-yellow-intense-fg ansi-bold">(</span>core<span class="ansi-yellow-intense-fg ansi-bold">.</span>_status_to_exception<span class="ansi-yellow-intense-fg ansi-bold">(</span>e<span class="ansi-yellow-intense-fg ansi-bold">.</span>code<span class="ansi-yellow-intense-fg ansi-bold">,</span> message<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   6844</span>   <span class="ansi-red-intense-fg ansi-bold"># pylint: enable=protected-access</span>
<span class="ansi-green-fg">   6845</span> 

<span class="ansi-green-intense-fg ansi-bold">~\miniconda3\envs\tensor_env\lib\site-packages\six.py</span> in <span class="ansi-cyan-fg">raise_from</span><span class="ansi-blue-intense-fg ansi-bold">(value, from_value)</span>

<span class="ansi-red-intense-fg ansi-bold">InvalidArgumentError</span>: Incompatible shapes: [5,4] vs. [5] [Op:RealDiv]</pre>
</div>
</div>

</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, there seems to be shape inconsistencies to the resultant sum tensor. Let's see the sum output for the axes in tensor.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 6., 22., 38., 54., 70.], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([40., 45., 50., 55.], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So I think, When we sum a tensor on a particular axis, the shape of the resultant tensor will end taking the shape with the other remaining axes, for example a tensor with shape <code>(5, 4 ,3)</code> when summed up along the third axis <code>(2)</code> the resultant tensor would be of shape <code>(5, 4)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The shapes for the tensors summed along the rest of the axes can be understood by the same.</p>
<div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">:</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When we do the division with the other resultant tensor, we can easily divide with it since the shapes follow the broadcasting rules</p>
<div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">-</span> <span class="mi">5</span> <span class="n">X</span> <span class="mi">4</span>
<span class="n">summed_a</span> <span class="o">-</span>     <span class="mi">4</span> 
<span class="n">result</span>   <span class="o">-</span> <span class="mi">5</span> <span class="n">X</span> <span class="mi">4</span>
</pre></div>
<p>The following is the result of the division</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[0.        , 0.02222222, 0.04      , 0.05454545],
       [0.1       , 0.11111111, 0.12      , 0.12727273],
       [0.2       , 0.2       , 0.2       , 0.2       ],
       [0.3       , 0.2888889 , 0.28      , 0.27272728],
       [0.4       , 0.37777779, 0.36      , 0.34545454]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A fellow learner suggested to reframe the question <a href="https://discuss.d2l.ai/t/linear-algebra/196/7?u=manimaran_p">here</a>, and said that the following code is what would have been expected by the one who framed the question.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">A</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[0.        , 0.16666667, 0.33333334, 0.5       ],
       [0.18181819, 0.22727273, 0.27272728, 0.3181818 ],
       [0.21052632, 0.23684211, 0.2631579 , 0.28947368],
       [0.22222222, 0.24074075, 0.25925925, 0.2777778 ],
       [0.22857143, 0.24285714, 0.25714287, 0.27142859]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see the shapes and values of the numerator and denominator of the above</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Numerator:  (5, 4)
Denominator: (5, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
 array([[ 6.],
        [22.],
        [38.],
        [54.],
        [70.]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
 array([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.],
        [12., 13., 14., 15.],
        [16., 17., 18., 19.]], dtype=float32)&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So if we compare the values, each value in <code>A</code> has been divided by the summation of each of it's rows</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="When-traveling-between-two-points-in-Manhattan,-what-is-the-distance-that-you-need-to-cover-in-terms-of-the-coordinates,-i.e.,-in-terms-of-avenues-and-streets?-Can-you-travel-diagonally?">
<a class="anchor" href="#When-traveling-between-two-points-in-Manhattan,-what-is-the-distance-that-you-need-to-cover-in-terms-of-the-coordinates,-i.e.,-in-terms-of-avenues-and-streets?-Can-you-travel-diagonally?" aria-hidden="true"><span class="octicon octicon-link"></span></a>When traveling between two points in Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally?<a class="anchor-link" href="#When-traveling-between-two-points-in-Manhattan,-what-is-the-distance-that-you-need-to-cover-in-terms-of-the-coordinates,-i.e.,-in-terms-of-avenues-and-streets?-Can-you-travel-diagonally?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A user <a href="https://discuss.d2l.ai/t/linear-algebra/30/7">suggested</a> to look at the streets of manhattan in google maps, to understand the question better,! as suggested the maps picture looked like a big piece of land cut into several small rectangular boxes, very much like 2d coordinate space, where each intersection of street can be treated as an point in that space.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at sample screenshot from google maps of manhattan streets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/Blog-Posts/images/copied_from_nb/../images/manhattan.png" alt="">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The question asks us to find the distance that we need to cover if we need to go from one point to another in terms of streets and avenues.<br>
Looks like there is a formula called <code>Manhattan distance</code> for a reason!</p>
<blockquote>
<p>The distance between two points measured along axes at right angles. In a plane with p1 at (x1, y1) and p2 at (x2, y2), it is |x1 - x2| + |y1 - y2|.
<sub>referred from <a href="https://xlinux.nist.gov/dads/HTML/manhattanDistance.html">here</a></sub>
and there is also a special geometry called taxicab geometry, with manhattan distance as its metric, there are some good images and content to understand better <a href="https://study.com/academy/lesson/taxicab-geometry-history-formula.html">here</a></p>
</blockquote>
<p>if we need to measure the distance in terms of streets and avenues, we need to consider them as dimensions (x(street),y(avenues)), let us consider that we are in the metro point in <strong>72nd</strong> street and we need to go to the Jones Wood Foundry in <strong>76th</strong> street.</p>
<p>Let's define them as coordinates,<br>
72nd street, 2nd Avenue -&gt; $(72, 2)$<br>
76th street, 1st Avenue -&gt; $(76, 1)$</p>
<p>so according to the formula the answer would be $(4, 1)$ ie 4 streets and 1 avenue, and we don't travel diagonally unless we are flying.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2.">
<a class="anchor" href="#The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2." aria-hidden="true"><span class="octicon octicon-link"></span></a>The summation outputs for tensor with shape (2, 3, 4) along axis 0, 1, and 2.<a class="anchor-link" href="#The-summation-outputs-for-tensor-with-shape-(2,-3,-4)-along-axis-0,-1,-and-2."> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I think I have answered this in the question about <code>A / A.sum(axis=1)</code>, that should apply to the any arbitrary shape, for this one it would turnout to be the following</p>
<div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm.">
<a class="anchor" href="#Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm." aria-hidden="true"><span class="octicon octicon-link"></span></a>Feed a tensor with 3 or more axes to the <code>linalg.norm</code>.<a class="anchor-link" href="#Feed-a-tensor-with-3-or-more-axes-to-the-linalg.norm."> </a>
</h3>
<h3 id="What-does-this-function-compute-for-tensors-of-arbitrary-shape?">
<a class="anchor" href="#What-does-this-function-compute-for-tensors-of-arbitrary-shape?" aria-hidden="true"><span class="octicon octicon-link"></span></a>What does this function compute for tensors of arbitrary shape?<a class="anchor-link" href="#What-does-this-function-compute-for-tensors-of-arbitrary-shape?"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a 3-d tensor</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(2, 2, 5), dtype=float32, numpy=
array([[[ 0.,  1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.,  9.]],

       [[10., 11., 12., 13., 14.],
        [15., 16., 17., 18., 19.]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(), dtype=float32, numpy=49.699093&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take an arbitrary shaped tensor</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(8, 1, 2, 5), dtype=float32, numpy=
array([[[[ 0.,  1.,  2.,  3.,  4.],
         [ 5.,  6.,  7.,  8.,  9.]]],


       [[[10., 11., 12., 13., 14.],
         [15., 16., 17., 18., 19.]]],


       [[[20., 21., 22., 23., 24.],
         [25., 26., 27., 28., 29.]]],


       [[[30., 31., 32., 33., 34.],
         [35., 36., 37., 38., 39.]]],


       [[[40., 41., 42., 43., 44.],
         [45., 46., 47., 48., 49.]]],


       [[[50., 51., 52., 53., 54.],
         [55., 56., 57., 58., 59.]]],


       [[[60., 61., 62., 63., 64.],
         [65., 66., 67., 68., 69.]]],


       [[[70., 71., 72., 73., 74.],
         [75., 76., 77., 78., 79.]]]], dtype=float32)&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(), dtype=float32, numpy=409.2432&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>tf.norm</code> still calculates the square root of squared sum of all numbers in the tensor, equivalent to the following</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
    <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">80</span><span class="p">)]</span>
        <span class="p">))</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: shape=(), dtype=float32, numpy=409.2432&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I am not sure if there was any change of behaviour expected in this, so I should try using <code>mxnet</code> to see if there is a difference in the above calculation of l2 norm.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="mani2106/Blog-Posts"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Blog-Posts/d2l.ai-exercises/deep-learning/tensorflow/2021/02/09/d2lai-exercises-pt3.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Blog-Posts/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Blog-Posts/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Manimaran Paneerselvam</li>
          <li><a class="u-email" href="mailto:manimaran_p@outlook.com">manimaran_p@outlook.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>This is where I write about my work on data science. I will also post Notebooks and sample codes to solve some interesting problems that I face everyday.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/mani2106" target="_blank" title="mani2106"><svg class="svg-icon grey"><use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/manimaran-p" target="_blank" title="manimaran-p"><svg class="svg-icon grey"><use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
