<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Wiki data extraction | Manimaran Paneerselvam’s blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Wiki data extraction" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Extracting data from wikipedia for language model" />
<meta property="og:description" content="Extracting data from wikipedia for language model" />
<link rel="canonical" href="https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html" />
<meta property="og:url" content="https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html" />
<meta property="og:site_name" content="Manimaran Paneerselvam’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-14T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Extracting data from wikipedia for language model","@type":"BlogPosting","headline":"Wiki data extraction","url":"https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html","datePublished":"2020-04-14T00:00:00-05:00","dateModified":"2020-04-14T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Blog-Posts/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mani2106.github.io/Blog-Posts/feed.xml" title="Manimaran Paneerselvam's blog" /><link rel="shortcut icon" type="image/x-icon" href="/Blog-Posts/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Wiki data extraction | Manimaran Paneerselvam’s blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Wiki data extraction" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Extracting data from wikipedia for language model" />
<meta property="og:description" content="Extracting data from wikipedia for language model" />
<link rel="canonical" href="https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html" />
<meta property="og:url" content="https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html" />
<meta property="og:site_name" content="Manimaran Paneerselvam’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-14T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Extracting data from wikipedia for language model","@type":"BlogPosting","headline":"Wiki data extraction","url":"https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html","datePublished":"2020-04-14T00:00:00-05:00","dateModified":"2020-04-14T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mani2106.github.io/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://mani2106.github.io/Blog-Posts/feed.xml" title="Manimaran Paneerselvam's blog" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Blog-Posts/">Manimaran Paneerselvam&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Blog-Posts/about/">About Me</a><a class="page-link" href="/Blog-Posts/search/">Search</a><a class="page-link" href="/Blog-Posts/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Wiki data extraction</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-14T00:00:00-05:00" itemprop="datePublished">
        Apr 14, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#data-cleaning">data-cleaning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Blog-Posts/categories/#language-model">language-model</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#extracting-data-from-wikipedia-for-language-model">Extracting data from wikipedia for language model</a></li>
<li class="toc-entry toc-h1"><a href="#setup-output-paths">Setup output paths</a></li>
<li class="toc-entry toc-h1"><a href="#request-file-from-wikipedia">Request file from wikipedia</a></li>
<li class="toc-entry toc-h1"><a href="#save-request-content-to-a-file">Save request content to a file</a></li>
<li class="toc-entry toc-h1"><a href="#clone-wiki-extractor-from-github">Clone wiki extractor from github</a></li>
<li class="toc-entry toc-h1"><a href="#use-wikiextractor-to-get-data-from-the-dump">Use wikiextractor to get data from the dump</a></li>
<li class="toc-entry toc-h1"><a href="#get-list-of-files-extracted-from-the-extraction-folder">Get list of files extracted from the extraction folder</a></li>
<li class="toc-entry toc-h1"><a href="#load-json-data-from-the-files">Load json data from the files</a></li>
<li class="toc-entry toc-h1"><a href="#preprocessing">Preprocessing</a>
<ul>
<li class="toc-entry toc-h2"><a href="#filter-english-words-from-text">Filter English words from text</a></li>
<li class="toc-entry toc-h2"><a href="#form-dataframe-and-apply-preprocessing">Form dataframe and apply preprocessing</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#store-the-output-in-compressed-format">Store the output in compressed format</a></li>
<li class="toc-entry toc-h1"><a href="#clean-up-the-downloaded-files-if-required">Clean up the downloaded files, (if required)</a></li>
</ul><h1 id="extracting-data-from-wikipedia-for-language-model">
<a class="anchor" href="#extracting-data-from-wikipedia-for-language-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extracting data from wikipedia for language model</h1>

<p>This post explains how I downloaded and extracted wiki dump archive using <a href="https://github.com/attardi/wikiextractor">wikiextractor</a>.</p>

<p>This code was used on a kaggle environment, which can be found <a href="https://www.kaggle.com/manimaranp/tamil-wiki-data-extraction">here</a>. You can fork and change as per your needs.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># For JSON data extraction
import json
# For path manipulations
from pathlib import Path
# For preprocessing
import string
# For deleting files and folders
import shutil

# To clone necessary files
import git
# To download the dump
import requests as req
# To use wikiextractor
import subprocess
# To clean and process data
import pandas as pd
</code></pre></div></div>

<h1 id="setup-output-paths">
<a class="anchor" href="#setup-output-paths" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setup output paths</h1>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DATA_PATH = Path('/kaggle/working/')
EXTRACTED_PATH = DATA_PATH/'extracted'
EXTRACTED_PATH.mkdir()
</code></pre></div></div>

<h1 id="request-file-from-wikipedia">
<a class="anchor" href="#request-file-from-wikipedia" aria-hidden="true"><span class="octicon octicon-link"></span></a>Request file from wikipedia</h1>
<p>You can use a different link here</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bzip_file = req.get('https://dumps.wikimedia.org/tawiki/latest/tawiki-latest-pages-articles.xml.bz2')
</code></pre></div></div>

<h1 id="save-request-content-to-a-file">
<a class="anchor" href="#save-request-content-to-a-file" aria-hidden="true"><span class="octicon octicon-link"></span></a>Save request content to a file</h1>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>with open(DATA_PATH/'tawiki-latest-pages-articles.xml.bz2', 'wb') as f:
    f.write(bzip_file.content)
</code></pre></div></div>

<h1 id="clone-wiki-extractor-from-github">
<a class="anchor" href="#clone-wiki-extractor-from-github" aria-hidden="true"><span class="octicon octicon-link"></span></a>Clone wiki extractor from github</h1>
<p>Thanks to <a href="https://github.com/attardi">attardi</a> and GitPython</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git.Git(str(DATA_PATH)).clone("https://github.com/attardi/wikiextractor.git")
</code></pre></div></div>

<h1 id="use-wikiextractor-to-get-data-from-the-dump">
<a class="anchor" href="#use-wikiextractor-to-get-data-from-the-dump" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use wikiextractor to get data from the dump</h1>
<p>This runs the wikiextractor cloned from github.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>run_stat = subprocess.run(
    ['python',
    # File to run
    str(DATA_PATH/'wikiextractor/WikiExtractor.py'),
    # Processing parameters get as json
    '-s', '--json',
    # Directory to store Extracted text
    '-o', str(DATA_PATH/'extracted'),
    # Archive file to extract from
    str(DATA_PATH/'tawiki-latest-pages-articles.xml.bz2')]
)
</code></pre></div></div>

<h1 id="get-list-of-files-extracted-from-the-extraction-folder">
<a class="anchor" href="#get-list-of-files-extracted-from-the-extraction-folder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Get list of files extracted from the extraction folder</h1>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>files_extracted = [str(f) for f in EXTRACTED_PATH.rglob("*/*")]
</code></pre></div></div>

<h1 id="load-json-data-from-the-files">
<a class="anchor" href="#load-json-data-from-the-files" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load json data from the files</h1>
<p>Since all files are stored as json we can load them like below, This gives us a list of dictionaries</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lang_text = [json.loads(line) 
             for _file in files_extracted 
             for line in open(_file)]
</code></pre></div></div>

<p>or this</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lang_text = []
for _file in files_extracted:
    with open(_file, 'r') as f:
        file_lines = f.readlines() 
    for line in file_lines:
        lang_text.append(json.loads(line))
</code></pre></div></div>

<h1 id="preprocessing">
<a class="anchor" href="#preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing</h1>
<p>You can use any of the following, or skip the preprocessing altogether if you wish so.</p>

<h2 id="filter-english-words-from-text">
<a class="anchor" href="#filter-english-words-from-text" aria-hidden="true"><span class="octicon octicon-link"></span></a>Filter English words from text</h2>

<p>Check each word after removing their punctuations, if it is an english word</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>filter_english = lambda text: ' '.join([word for word in text.split() if word.translate(str.maketrans('', '', string.punctuation)).isalpha() is False])
</code></pre></div></div>

<p>or</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def filter_english(text):
    words = []
    # Spltting words
    for word in text.split():
        # Replace symbols
        word = word.translate(str.maketrans('', '', string.punctuation))
        if not word.isalpha():
            words.append(word)
    return ' '.join(words)
</code></pre></div></div>

<h2 id="form-dataframe-and-apply-preprocessing">
<a class="anchor" href="#form-dataframe-and-apply-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Form dataframe and apply preprocessing</h2>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Since we have a list of dictionaries.
lang_df = pd.DataFrame(lang_text)
lang_df['text'] = lang_df['text'].apply(filter_english)
</code></pre></div></div>

<h1 id="store-the-output-in-compressed-format">
<a class="anchor" href="#store-the-output-in-compressed-format" aria-hidden="true"><span class="octicon octicon-link"></span></a>Store the output in compressed format</h1>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lang_df.to_csv(DATA_PATH/'filtered_data.csv.tar.gz', header=True)
</code></pre></div></div>

<p>The above saved file can be loaded with <code class="highlighter-rouge">pd.read_csv</code>.</p>

<p>You can find the full code for this in <a href="https://gist.github.com/mani2106/97c0af61c9fde6e6cd7f6304f1b593af">Github gist</a> or with the output in <a href="https://www.kaggle.com/manimaranp/tamil-wiki-data-extraction">kaggle</a>.</p>

<h1 id="clean-up-the-downloaded-files-if-required">
<a class="anchor" href="#clean-up-the-downloaded-files-if-required" aria-hidden="true"><span class="octicon octicon-link"></span></a>Clean up the downloaded files, (if required)</h1>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>shutil.rmtree(str(EXTRACTED_PATH))
shutil.rmtree(str(DATA_PATH/'wikiextractor'))
Path(DATA_PATH/'tawiki-latest-pages-articles.xml.bz2').unlink()
</code></pre></div></div>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="mani2106/Blog-Posts"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Blog-Posts/data-cleaning/language-model/2020/04/14/wiki-data-extraction.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Blog-Posts/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Blog-Posts/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>This is where I write about my work on data science. I will also post Notebooks and sample codes to solve some interesting problems that I face everyday.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/mani2106" title="mani2106"><svg class="svg-icon grey"><use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/manimaran-p" title="manimaran-p"><svg class="svg-icon grey"><use xlink:href="/Blog-Posts/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
